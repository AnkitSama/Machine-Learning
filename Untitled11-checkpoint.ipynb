{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "# scipy.special for the sigmoid function expit(), and its inverse logit()\n",
    "import scipy.special\n",
    "# library for plotting arrays\n",
    "import matplotlib.pyplot\n",
    "# ensure the plots are inside this notebook, not an external window\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural network class definition\n",
    "class neuralNetwork:\n",
    "    \n",
    "    \n",
    "    # initialise the neural network\n",
    "    def __init__(self, inputnodes, hiddennodes, outputnodes, learningrate):\n",
    "        # set number of nodes in each input, hidden, output layer\n",
    "        self.inodes = inputnodes\n",
    "        self.hnodes = hiddennodes\n",
    "        self.onodes = outputnodes\n",
    "        \n",
    "        # link weight matrices, wih and who\n",
    "        # weights inside the arrays are w_i_j, where link is from node i to node j in the next layer\n",
    "        # w11 w21\n",
    "        # w12 w22 etc \n",
    "        self.wih = numpy.random.normal(0.0, pow(self.inodes, -0.5), (self.hnodes, self.inodes))\n",
    "        self.who = numpy.random.normal(0.0, pow(self.hnodes, -0.5), (self.onodes, self.hnodes))\n",
    "\n",
    "        # learning rate\n",
    "        self.lr = learningrate\n",
    "        \n",
    "        # activation function is the sigmoid function\n",
    "        self.activation_function = lambda x: scipy.special.expit(x)\n",
    "        self.inverse_activation_function = lambda x: scipy.special.logit(x)\n",
    "        \n",
    "        pass\n",
    "\n",
    "    \n",
    "    # train the neural network\n",
    "    def train(self, inputs_list, targets_list):\n",
    "        # convert inputs list to 2d array\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        targets = numpy.array(targets_list, ndmin=2).T\n",
    "        \n",
    "        # calculate signals into hidden layer\n",
    "        hidden_inputs = numpy.dot(self.wih, inputs)\n",
    "        # calculate the signals emerging from hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        # calculate signals into final output layer\n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "        # calculate the signals emerging from final output layer\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        # output layer error is the (target - actual)\n",
    "        output_errors = targets - final_outputs\n",
    "        # hidden layer error is the output_errors, split by weights, recombined at hidden nodes\n",
    "        hidden_errors = numpy.dot(self.who.T, output_errors) \n",
    "        \n",
    "        # update the weights for the links between the hidden and output layers\n",
    "        self.who += self.lr * numpy.dot((output_errors * final_outputs * (1.0 - final_outputs)), numpy.transpose(hidden_outputs))\n",
    "        \n",
    "        # update the weights for the links between the input and hidden layers\n",
    "        self.wih += self.lr * numpy.dot((hidden_errors * hidden_outputs * (1.0 - hidden_outputs)), numpy.transpose(inputs))\n",
    "        \n",
    "        pass\n",
    "\n",
    "    \n",
    "    # query the neural network\n",
    "    def query(self, inputs_list):\n",
    "        # convert inputs list to 2d array\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        \n",
    "        # calculate signals into hidden layer\n",
    "        hidden_inputs = numpy.dot(self.wih, inputs)\n",
    "        # calculate the signals emerging from hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        # calculate signals into final output layer\n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "        # calculate the signals emerging from final output layer\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        return final_outputs\n",
    "    \n",
    "    \n",
    "    # backquery the neural network\n",
    "    # we'll use the same termnimology to each item, \n",
    "    # eg target are the values at the right of the network, albeit used as input\n",
    "    # eg hidden_output is the signal to the right of the middle nodes\n",
    "    def backquery(self, targets_list):\n",
    "        # transpose the targets list to a vertical array\n",
    "        final_outputs = numpy.array(targets_list, ndmin=2).T\n",
    "        \n",
    "        # calculate the signal into the final output layer\n",
    "        final_inputs = self.inverse_activation_function(final_outputs)\n",
    "\n",
    "        # calculate the signal out of the hidden layer\n",
    "        hidden_outputs = numpy.dot(self.who.T, final_inputs)\n",
    "        # scale them back to 0.01 to .99\n",
    "        hidden_outputs -= numpy.min(hidden_outputs)\n",
    "        hidden_outputs /= numpy.max(hidden_outputs)\n",
    "        hidden_outputs *= 0.98\n",
    "        hidden_outputs += 0.01\n",
    "        \n",
    "        # calculate the signal into the hidden layer\n",
    "        hidden_inputs = self.inverse_activation_function(hidden_outputs)\n",
    "        \n",
    "        # calculate the signal out of the input layer\n",
    "        inputs = numpy.dot(self.wih.T, hidden_inputs)\n",
    "        # scale them back to 0.01 to .99\n",
    "        inputs -= numpy.min(inputs)\n",
    "        inputs /= numpy.max(inputs)\n",
    "        inputs *= 0.98\n",
    "        inputs += 0.01\n",
    "        \n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of input, hidden and output nodes\n",
    "input_nodes = 784\n",
    "hidden_nodes = 200\n",
    "output_nodes = 10\n",
    "\n",
    "# learning rate\n",
    "learning_rate = 0.1\n",
    "\n",
    "# create instance of neural network\n",
    "n = neuralNetwork(input_nodes,hidden_nodes,output_nodes, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the mnist training data CSV file into a list\n",
    "training_data_file = open(\"Downloads/mnist_train.csv\", 'r')\n",
    "training_data_list = training_data_file.readlines()\n",
    "training_data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the neural network\n",
    "\n",
    "# epochs is the number of times the training data set is used for training\n",
    "epochs = 5\n",
    "\n",
    "for e in range(epochs):\n",
    "    # go through all records in the training data set\n",
    "    for record in training_data_list:\n",
    "        # split the record by the ',' commas\n",
    "        all_values = record.split(',')\n",
    "        # scale and shift the inputs\n",
    "        inputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "        # create the target output values (all 0.01, except the desired label which is 0.99)\n",
    "        targets = numpy.zeros(output_nodes) + 0.01\n",
    "        # all_values[0] is the target label for this record\n",
    "        targets[int(all_values[0])] = 0.99\n",
    "        n.train(inputs, targets)\n",
    "        pass\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the mnist test data CSV file into a list\n",
    "test_data_file = open(\"Downloads/mnist_test.csv\", 'r')\n",
    "test_data_list = test_data_file.readlines()\n",
    "test_data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the neural network\n",
    "\n",
    "# scorecard for how well the network performs, initially empty\n",
    "scorecard = []\n",
    "\n",
    "# go through all the records in the test data set\n",
    "for record in test_data_list:\n",
    "    # split the record by the ',' commas\n",
    "    all_values = record.split(',')\n",
    "    # correct answer is first value\n",
    "    correct_label = int(all_values[0])\n",
    "    # scale and shift the inputs\n",
    "    inputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "    # query the network\n",
    "    outputs = n.query(inputs)\n",
    "    # the index of the highest value corresponds to the label\n",
    "    label = numpy.argmax(outputs)\n",
    "    # append correct or incorrect to list\n",
    "    if (label == correct_label):\n",
    "        # network's answer matches correct answer, add 1 to scorecard\n",
    "        scorecard.append(1)\n",
    "    else:\n",
    "        # network's answer doesn't match correct answer, add 0 to scorecard\n",
    "        scorecard.append(0)\n",
    "        pass\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance =  0.9731\n"
     ]
    }
   ],
   "source": [
    "# calculate the performance score, the fraction of correct answers\n",
    "scorecard_array = numpy.asarray(scorecard)\n",
    "print (\"performance = \", scorecard_array.sum() / scorecard_array.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x22e45cb8670>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# run the network backwards, given a label, see what image it produces\n",
    "\n",
    "# label to test\n",
    "label = 0\n",
    "# create the output signals for this label\n",
    "targets = numpy.zeros(output_nodes) + 0.01\n",
    "# all_values[0] is the target label for this record\n",
    "targets[label] = 0.99\n",
    "print(targets)\n",
    "\n",
    "# get image data\n",
    "image_data = n.backquery(targets)\n",
    "\n",
    "# plot image data\n",
    "matplotlib.pyplot.imshow(image_data.reshape(28,28), cmap='Greys', interpolation='None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
